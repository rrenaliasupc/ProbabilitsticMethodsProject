{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd64f25e",
   "metadata": {},
   "source": [
    "# Markov Chains for Weather Prediction\n",
    "## Authors: Eric Roy, Pau de las Heras, Ricard Renalias\n",
    "\n",
    "Aplication of Markov Chains models for weather Predition in Manresa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f5f5e9",
   "metadata": {},
   "source": [
    "---\n",
    "### Historical Meteo Data\n",
    "Retrieve meteorological data from a station near Manresa.\n",
    "\n",
    "The data is sourced from GenCat Open Data (https://analisi.transparenciacatalunya.cat).\n",
    "\n",
    "We use the database of the meteorological station XEMA:\n",
    "https://analisi.transparenciacatalunya.cat/Medi-Ambient/Dades-meteorol-giques-de-la-XEMA/nzvn-apee/about_data.\n",
    "\n",
    "The nearest meteorological station to Manresa is \"Sant Salvador de Guardiola\" (Code: CL).\n",
    "\n",
    "We analyze the observed data and focus on the variable \"Precipitaci√≥\" (Code: 35).\n",
    "\n",
    "A filter is created (https://analisi.transparenciacatalunya.cat/Medi-Ambient/Dades-meteorol-giques-de-la-XEMA/nzvn-apee/explore/query/SELECT%0A%20%20%60id%60%2C%0A%20%20%60codi_estacio%60%2C%0A%20%20%60codi_variable%60%2C%0A%20%20%60data_lectura%60%2C%0A%20%20%60data_extrem%60%2C%0A%20%20%60valor_lectura%60%2C%0A%20%20%60codi_estat%60%2C%0A%20%20%60codi_base%60%0AWHERE%0A%20%20caseless_one_of%28%60codi_estacio%60%2C%20%22CL%22%29%0A%20%20AND%20caseless_one_of%28%60codi_variable%60%2C%20%2235%22%29/page/filter), and the data is exported as a CSV file.\n",
    "\n",
    "As a result, we obtain:\n",
    "`dades_meteorologiques.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f202e68a",
   "metadata": {},
   "source": [
    "---\n",
    "We group data by date and sum the dayly precipitation\n",
    "---\n",
    "We import the data and create a table by assuming that:\n",
    "- Sunny: If precipitation is 0\n",
    "- Cloudy: If precipitation is under 5\n",
    "- Rainy: If precipitation is over 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2720deb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ID CODI_ESTACIO  CODI_VARIABLE            DATA_LECTURA  \\\n",
      "0  CL350101090000           CL             35  01/01/2009 12:00:00 AM   \n",
      "1  CL350101090030           CL             35  01/01/2009 12:30:00 AM   \n",
      "2  CL350101090100           CL             35  01/01/2009 01:00:00 AM   \n",
      "3  CL350101090130           CL             35  01/01/2009 01:30:00 AM   \n",
      "4  CL350101090200           CL             35  01/01/2009 02:00:00 AM   \n",
      "\n",
      "   DATA_EXTREM  VALOR_LECTURA CODI_ESTAT CODI_BASE  \n",
      "0          NaN            0.0          V        SH  \n",
      "1          NaN            0.0          V        SH  \n",
      "2          NaN            0.0          V        SH  \n",
      "3          NaN            0.0          V        SH  \n",
      "4          NaN            0.0          V        SH  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rrena\\AppData\\Local\\Temp\\ipykernel_16276\\2415825590.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['DATE'] = pd.to_datetime(df['DATA_LECTURA']).dt.date\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ID CODI_ESTACIO  CODI_VARIABLE            DATA_LECTURA  \\\n",
      "0  CL350101090000           CL             35  01/01/2009 12:00:00 AM   \n",
      "1  CL350101090030           CL             35  01/01/2009 12:30:00 AM   \n",
      "2  CL350101090100           CL             35  01/01/2009 01:00:00 AM   \n",
      "3  CL350101090130           CL             35  01/01/2009 01:30:00 AM   \n",
      "4  CL350101090200           CL             35  01/01/2009 02:00:00 AM   \n",
      "\n",
      "   DATA_EXTREM  VALOR_LECTURA CODI_ESTAT CODI_BASE        DATE  \n",
      "0          NaN            0.0          V        SH  2009-01-01  \n",
      "1          NaN            0.0          V        SH  2009-01-01  \n",
      "2          NaN            0.0          V        SH  2009-01-01  \n",
      "3          NaN            0.0          V        SH  2009-01-01  \n",
      "4          NaN            0.0          V        SH  2009-01-01  \n",
      "         DATE  VALOR_LECTURA\n",
      "0  2009-01-01            0.1\n",
      "1  2009-01-02            9.8\n",
      "2  2009-01-03            1.7\n",
      "3  2009-01-04            0.4\n",
      "4  2009-01-05            2.0\n",
      "           Sunny    Cloudy     Rainy\n",
      "Sunny   0.799111  0.139556  0.061333\n",
      "Cloudy  0.642012  0.251479  0.106509\n",
      "Rainy   0.541578  0.277186  0.181237\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('dades_meteorologiques.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(df.head())\n",
    "\n",
    "# Create a new column ONLY date from DATA_LECTURA\n",
    "df['DATE'] = pd.to_datetime(df['DATA_LECTURA']).dt.date\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "#Create a new dataframe with the date and precipitation values grouped by date and sum of precipitation\n",
    "df = df.groupby('DATE', as_index=False)['VALOR_LECTURA'].sum()\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Define states based on precipitation levels\n",
    "def classify_state(precipitation):\n",
    "    if precipitation == 0:\n",
    "        return 'Sunny'\n",
    "    elif precipitation < 5:\n",
    "        return 'Cloudy'\n",
    "    else:\n",
    "        return 'Rainy'\n",
    "\n",
    "# Apply the classification function to create a new column 'State'\n",
    "df['State'] = df['VALOR_LECTURA'].apply(classify_state)\n",
    "\n",
    "# Create the transition matrix\n",
    "states = ['Sunny', 'Cloudy', 'Rainy']\n",
    "transition_matrix = pd.DataFrame(0, index=states, columns=states)\n",
    "\n",
    "# Populate the transition matrix with counts\n",
    "for i in range(len(df) - 1):\n",
    "    current_state = df.loc[i, 'State']\n",
    "    next_state = df.loc[i + 1, 'State']\n",
    "    transition_matrix.loc[current_state, next_state] += 1\n",
    "\n",
    "# Convert counts to probabilities\n",
    "transition_probabilities = transition_matrix.div(transition_matrix.sum(axis=1), axis=0)\n",
    "\n",
    "# Display the transition probability matrix\n",
    "print(transition_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b722822",
   "metadata": {},
   "source": [
    "---\n",
    "Create stationary distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6351f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75233049, 0.16929048, 0.07837903])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate the stationary distribution\n",
    "def stationary(mat):\n",
    "    eigvals, eigvecs = np.linalg.eig(mat.T)\n",
    "    stationary_vector = eigvecs[:, np.isclose(eigvals, 1)]\n",
    "    stationary_vector = stationary_vector[:, 0]\n",
    "    stationary_distribution = stationary_vector / stationary_vector.sum()\n",
    "    return stationary_distribution.real\n",
    "\n",
    "# Calculate the stationary distribution\n",
    "stationary_distribution = stationary(transition_probabilities.values)\n",
    "\n",
    "# Limiting distribution\n",
    "limiting_distribution = stationary_distribution\n",
    "limiting_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754cfb58",
   "metadata": {},
   "source": [
    "---\n",
    "Calculate the smallest power m of a transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "870d53bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to determine the smallest power m of a transition matrix\n",
    "# with the property that P^m = P^(m+1)\n",
    "def power_func(matrix):\n",
    "    for m in range(1, 1001):\n",
    "        mat1 = np.round(np.linalg.matrix_power(matrix, m), decimals=9)\n",
    "        mat2 = np.round(np.linalg.matrix_power(matrix, m + 1), decimals=9)\n",
    "        if np.allclose(mat1, mat2, atol=0):\n",
    "            return m\n",
    "\n",
    "# Calculate the power\n",
    "power = power_func(transition_probabilities.values)\n",
    "power"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a24424",
   "metadata": {},
   "source": [
    "---\n",
    "Calculate the limiting Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a01a4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75233049, 0.16929048, 0.07837903],\n",
       "       [0.75233049, 0.16929048, 0.07837903],\n",
       "       [0.75233049, 0.16929048, 0.07837903]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Limiting Matrix is:\n",
    "P_lim = np.linalg.matrix_power(transition_probabilities.values, 37)\n",
    "P_lim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d807294b",
   "metadata": {},
   "source": [
    "---\n",
    "Generate random simulation states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f062906f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute frequency distribution:\n",
      "Sunny     39\n",
      "Rainy     32\n",
      "Cloudy    29\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Relative frequency distribution:\n",
      "Sunny     0.39\n",
      "Rainy     0.32\n",
      "Cloudy    0.29\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Set the seed for reproducibility\n",
    "np.random.seed(123454)\n",
    "\n",
    "# Simulate results with the three states\n",
    "simulation_results = np.random.choice(\n",
    "    a=states,  # Use the states ['Sunny', 'Cloudy', 'Rainy']\n",
    "    size=100,\n",
    "    replace=True,\n",
    "    p=[1/3, 1/3, 1/3]  # Equal probabilities for each state\n",
    ")\n",
    "\n",
    "# Absolute frequency distribution\n",
    "abs_freq_distrib = pd.Series(simulation_results).value_counts()\n",
    "print(\"Absolute frequency distribution:\")\n",
    "print(abs_freq_distrib)\n",
    "\n",
    "# Relative frequency distribution\n",
    "rel_freq_distrib = pd.Series(simulation_results).value_counts(normalize=True)\n",
    "print(\"\\nRelative frequency distribution:\")\n",
    "print(rel_freq_distrib)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbda4879",
   "metadata": {},
   "source": [
    "---\n",
    "Create a simulation baed on transition probabilities matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ebadd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial distribution: [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n",
      "First few simulated chains:\n",
      "[['Rainy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Cloudy', 'Cloudy', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Cloudy', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Rainy', 'Rainy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Rainy', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Cloudy', 'Sunny', 'Cloudy', 'Sunny', 'Cloudy', 'Cloudy', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny'], ['Cloudy', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Rainy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Rainy', 'Sunny', 'Cloudy', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Rainy', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Sunny', 'Cloudy', 'Rainy', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Cloudy'], ['Rainy', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Cloudy', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Rainy', 'Cloudy', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Rainy', 'Sunny', 'Rainy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Cloudy', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Rainy', 'Sunny', 'Cloudy', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Cloudy', 'Rainy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Sunny', 'Sunny', 'Sunny', 'Sunny'], ['Sunny', 'Cloudy', 'Cloudy', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Rainy', 'Cloudy', 'Rainy', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Sunny', 'Cloudy', 'Cloudy', 'Sunny', 'Sunny', 'Cloudy', 'Rainy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Cloudy', 'Cloudy', 'Sunny', 'Cloudy', 'Rainy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Rainy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny'], ['Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Rainy', 'Rainy', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Rainy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Rainy', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny', 'Rainy', 'Sunny', 'Cloudy', 'Sunny', 'Sunny', 'Rainy', 'Cloudy', 'Sunny', 'Sunny']]\n",
      "First few states in the simulation:\n",
      "['Rainy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Rainy', 'Cloudy', 'Cloudy', 'Cloudy', 'Sunny', 'Sunny', 'Sunny', 'Sunny', 'Cloudy', 'Sunny']\n",
      "Absolute frequency distribution:\n",
      "Sunny     754259\n",
      "Cloudy    173315\n",
      "Rainy      82426\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Relative frequency distribution:\n",
      "Sunny     0.746791\n",
      "Cloudy    0.171599\n",
      "Rainy     0.081610\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Define the initial distribution with equal probabilities for the three states\n",
    "initial = [1/3, 1/3, 1/3]  # Three states with equal probabilities\n",
    "print(\"Initial distribution:\", initial)\n",
    "\n",
    "# Define the states\n",
    "states = ['Sunny', 'Cloudy', 'Rainy']\n",
    "\n",
    "# Markov simulation function\n",
    "def markov(init, matrix, n, labels=None):\n",
    "    if labels is None:\n",
    "        labels = list(range(1, len(init) + 1))\n",
    "    \n",
    "    # Initialize the simulation list\n",
    "    simlist = [0] * (n + 1)\n",
    "    \n",
    "    # First state based on the initial distribution\n",
    "    simlist[0] = np.random.choice(len(init), p=init)\n",
    "    \n",
    "    # Simulate the Markov chain\n",
    "    for i in range(1, n + 1):\n",
    "        simlist[i] = np.random.choice(len(init), p=matrix[simlist[i - 1]])\n",
    "    \n",
    "    # Map the states to their labels\n",
    "    return [labels[state] for state in simlist]\n",
    "\n",
    "# Transition matrix (already defined as P)\n",
    "P_matrix = transition_probabilities.values\n",
    "\n",
    "# Simulate 10,000 Markov chains\n",
    "replicate_sim = [markov(initial, P_matrix, 100, states) for _ in range(10000)]\n",
    "\n",
    "\n",
    "# Flatten the results for frequency distribution\n",
    "flattened_sim = [state for chain in replicate_sim for state in chain]\n",
    "\n",
    "# Display the first few simulated chains\n",
    "print(\"First few simulated chains:\")\n",
    "print(replicate_sim[:5])\n",
    "# Display the first few states in the simulation\n",
    "print(\"First few states in the simulation:\")\n",
    "print(flattened_sim[:20])\n",
    "\n",
    "\n",
    "# Absolute frequency distribution\n",
    "distr_abs_freq_2 = pd.Series(flattened_sim).value_counts()\n",
    "print(\"Absolute frequency distribution:\")\n",
    "print(distr_abs_freq_2)\n",
    "\n",
    "# Relative frequency distribution\n",
    "rel_freq_distrib_2 = pd.Series(flattened_sim).value_counts(normalize=True)\n",
    "print(\"\\nRelative frequency distribution:\")\n",
    "print(rel_freq_distrib_2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
